"""
This type stub file was generated by pyright.
"""

from typing import Any
from aiokafka.structs import ConsumerRecord
from avro.datafile import DataFileReader


log = ...
UNKNOWN_OFFSET = ...
READ_UNCOMMITTED = ...
READ_COMMITTED = ...

class OffsetResetStrategy:
    LATEST = ...
    EARLIEST = ...
    NONE = ...
    @classmethod
    def from_str(cls, name):  # -> Literal[-1, -2, 0]:
        ...
    @classmethod
    def to_str(cls, value):  # -> str:
        ...

class FetchResult:
    def __init__(self, tp, *, assignment, partition_records, backoff) -> None: ...
    def calculate_backoff(self):  # -> Literal[0]:
        ...
    def check_assignment(self, tp):  # -> bool:
        ...
    def getone(self):  # -> None:
        ...
    def getall(self, max_records=...):  # -> list[Any]:
        ...
    def has_more(self):  # -> bool:
        ...
    def __repr__(self):  # -> str:
        ...

class FetchError:
    def __init__(self, *, error, backoff) -> None: ...
    def calculate_backoff(self):  # -> Literal[0]:
        ...
    def check_raise(self): ...
    def __repr__(self):  # -> str:
        ...

class PartitionRecords:
    def __init__(
        self,
        tp,
        records,
        aborted_transactions,
        fetch_offset,
        key_deserializer,
        value_deserializer,
        check_crcs,
        isolation_level,
    ) -> None: ...
    def __iter__(self):  # -> Self:
        ...
    def __next__(self):  # -> ConsumerRecord[Any, Any]:
        ...

class Fetcher:
    """Initialize a Kafka Message Fetcher.

    Parameters
    ----------
        client (AIOKafkaClient): kafka client
        subscription (SubscriptionState): instance of SubscriptionState
            located in aiokafka.consumer.subscription_state
        key_deserializer (callable): Any callable that takes a
            raw message key and returns a deserialized key.
        value_deserializer (callable, optional): Any callable that takes a
            raw message value and returns a deserialized value.
        fetch_min_bytes (int): Minimum amount of data the server should
            return for a fetch request, otherwise wait up to
            fetch_max_wait_ms for more data to accumulate. Default: 1.
        fetch_max_bytes (int): The maximum amount of data the server should
            return for a fetch request. This is not an absolute maximum, if
            the first message in the first non-empty partition of the fetch
            is larger than this value, the message will still be returned
            to ensure that the consumer can make progress. NOTE: consumer
            performs fetches to multiple brokers in parallel so memory
            usage will depend on the number of brokers containing
            partitions for the topic.
            Supported Kafka version >= 0.10.1.0. Default: 52428800 (50 Mb).
        fetch_max_wait_ms (int): The maximum amount of time in milliseconds
            the server will block before answering the fetch request if
            there isn't sufficient data to immediately satisfy the
            requirement given by fetch_min_bytes. Default: 500.
        max_partition_fetch_bytes (int): The maximum amount of data
            per-partition the server will return. The maximum total memory
            used for a request = #partitions * max_partition_fetch_bytes.
            This size must be at least as large as the maximum message size
            the server allows or else it is possible for the producer to
            send messages larger than the consumer can fetch. If that
            happens, the consumer can get stuck trying to fetch a large
            message on a certain partition. Default: 1048576.
        check_crcs (bool): Automatically check the CRC32 of the records
            consumed. This ensures no on-the-wire or on-disk corruption to
            the messages occurred. This check adds some overhead, so it may
            be disabled in cases seeking extreme performance. Default: True
        fetcher_timeout (float): Maximum polling interval in the background
            fetching routine. Default: 0.2
        prefetch_backoff (float): number of seconds to wait until
            consumption of partition is paused. Paused partitions will not
            request new data from Kafka server (will not be included in
            next poll request).
        auto_offset_reset (str): A policy for resetting offsets on
            OffsetOutOfRange errors: 'earliest' will move to the oldest
            available message, 'latest' will move to the most recent. Any
            ofther value will raise the exception. Default: 'latest'.
        isolation_level (str): Controls how to read messages written
            transactionally. See consumer description.

    """

    def __init__(
        self,
        client,
        subscriptions,
        *,
        key_deserializer=...,
        value_deserializer=...,
        fetch_min_bytes=...,
        fetch_max_bytes=...,
        fetch_max_wait_ms=...,
        max_partition_fetch_bytes=...,
        check_crcs=...,
        fetcher_timeout=...,
        prefetch_backoff=...,
        retry_backoff_ms=...,
        auto_offset_reset=...,
        isolation_level=...,
    ) -> None: ...
    async def close(self):  # -> None:
        ...
    @property
    def error_future(self):  # -> Task[None]:
        ...
    async def next_record(self, partitions):
        """Return one fetched records

        This method will contain a little overhead as we will do more work this
        way:
            * Notify prefetch routine per every consumed partition
            * Assure message marked for autocommit

        """

    async def fetched_records(self, partitions, timeout=..., max_records=...):  # -> dict[Any, Any]:
        """Returns previously fetched records and updates consumed offsets."""

    async def get_offsets_by_times(self, timestamps, timeout_ms):  # -> dict[Any, Any]:
        ...
    async def beginning_offsets(self, partitions, timeout_ms):  # -> dict[Any, Any]:
        ...
    async def end_offsets(self, partitions, timeout_ms):  # -> dict[Any, Any]:
        ...
    def request_offset_reset(self, tps, strategy):  # -> Future[list[Any]]:
        """Force a position reset. Called from Consumer of `seek_to_*` API's."""

    def seek_to(self, tp, offset):  # -> None:
        """Force a position change to specific offset. Called from
        `Consumer.seek()` API.
        """
